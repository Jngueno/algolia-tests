[2023-05-23T13:24:44.710+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: algolia_test.download_csv_file scheduled__2019-04-03T00:00:00+00:00 [queued]>
[2023-05-23T13:24:44.721+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: algolia_test.download_csv_file scheduled__2019-04-03T00:00:00+00:00 [queued]>
[2023-05-23T13:24:44.721+0000] {taskinstance.py:1362} INFO - 
--------------------------------------------------------------------------------
[2023-05-23T13:24:44.722+0000] {taskinstance.py:1363} INFO - Starting attempt 1 of 1
[2023-05-23T13:24:44.724+0000] {taskinstance.py:1364} INFO - 
--------------------------------------------------------------------------------
[2023-05-23T13:24:44.772+0000] {taskinstance.py:1383} INFO - Executing <Task(_PythonDecoratedOperator): download_csv_file> on 2019-04-03 00:00:00+00:00
[2023-05-23T13:24:44.787+0000] {standard_task_runner.py:55} INFO - Started process 4216 to run task
[2023-05-23T13:24:44.799+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'algolia_test', 'download_csv_file', 'scheduled__2019-04-03T00:00:00+00:00', '--job-id', '28', '--raw', '--subdir', 'DAGS_FOLDER/algolia-dag.py', '--cfg-path', '/tmp/tmp3zangajb']
[2023-05-23T13:24:44.802+0000] {standard_task_runner.py:83} INFO - Job 28: Subtask download_csv_file
[2023-05-23T13:24:44.934+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/configuration.py:545: DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
  option = self._get_environment_variables(deprecated_key, deprecated_section, key, section)

[2023-05-23T13:24:45.150+0000] {task_command.py:376} INFO - Running <TaskInstance: algolia_test.download_csv_file scheduled__2019-04-03T00:00:00+00:00 [running]> on host c3034470bbd8
[2023-05-23T13:24:45.436+0000] {taskinstance.py:1592} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=algolia_test
AIRFLOW_CTX_TASK_ID=download_csv_file
AIRFLOW_CTX_EXECUTION_DATE=2019-04-03T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2019-04-03T00:00:00+00:00
[2023-05-23T13:24:45.438+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:204: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2023-05-23T13:24:45.439+0000] {logging_mixin.py:137} INFO - 2019-04-03
[2023-05-23T13:24:46.339+0000] {taskinstance.py:1851} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/decorators/base.py", line 188, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 193, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/algolia-dag.py", line 33, in download_csv_file
    src_client.download_file(object_key, f'/tmp/{object_key}')
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/s3/inject.py", line 283, in bucket_download_file
    Config=Config,
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/s3/inject.py", line 195, in download_file
    callback=Callback,
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/s3/transfer.py", line 320, in download_file
    future.result()
  File "/home/airflow/.local/lib/python3.7/site-packages/s3transfer/futures.py", line 103, in result
    return self._coordinator.result()
  File "/home/airflow/.local/lib/python3.7/site-packages/s3transfer/futures.py", line 266, in result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/s3transfer/tasks.py", line 269, in _main
    self._submit(transfer_future=transfer_future, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/s3transfer/download.py", line 357, in _submit
    **transfer_future.meta.call_args.extra_args,
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 515, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 934, in _make_api_call
    raise error_class(parsed_response, operation_name)
botocore.exceptions.ClientError: An error occurred (404) when calling the HeadObject operation: Not Found
[2023-05-23T13:24:46.356+0000] {taskinstance.py:1406} INFO - Marking task as FAILED. dag_id=algolia_test, task_id=download_csv_file, execution_date=20190403T000000, start_date=20230523T132444, end_date=20230523T132446
[2023-05-23T13:24:46.405+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 28 for task download_csv_file (An error occurred (404) when calling the HeadObject operation: Not Found; 4216)
[2023-05-23T13:24:46.475+0000] {local_task_job.py:159} INFO - Task exited with return code 1
[2023-05-23T13:24:46.501+0000] {taskinstance.py:2623} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-05-23T22:11:38.457+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: algolia_test.download_csv_file scheduled__2019-04-03T00:00:00+00:00 [queued]>
[2023-05-23T22:11:38.496+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: algolia_test.download_csv_file scheduled__2019-04-03T00:00:00+00:00 [queued]>
[2023-05-23T22:11:38.510+0000] {taskinstance.py:1362} INFO - 
--------------------------------------------------------------------------------
[2023-05-23T22:11:38.511+0000] {taskinstance.py:1363} INFO - Starting attempt 1 of 1
[2023-05-23T22:11:38.511+0000] {taskinstance.py:1364} INFO - 
--------------------------------------------------------------------------------
[2023-05-23T22:11:38.552+0000] {taskinstance.py:1383} INFO - Executing <Task(_PythonDecoratedOperator): download_csv_file> on 2019-04-03 00:00:00+00:00
[2023-05-23T22:11:38.577+0000] {standard_task_runner.py:55} INFO - Started process 338 to run task
[2023-05-23T22:11:38.585+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'algolia_test', 'download_csv_file', 'scheduled__2019-04-03T00:00:00+00:00', '--job-id', '71', '--raw', '--subdir', 'DAGS_FOLDER/algolia-dag.py', '--cfg-path', '/tmp/tmp0cx5ogq2']
[2023-05-23T22:11:38.590+0000] {standard_task_runner.py:83} INFO - Job 71: Subtask download_csv_file
[2023-05-23T22:11:38.658+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/configuration.py:545: DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
  option = self._get_environment_variables(deprecated_key, deprecated_section, key, section)

[2023-05-23T22:11:38.859+0000] {task_command.py:376} INFO - Running <TaskInstance: algolia_test.download_csv_file scheduled__2019-04-03T00:00:00+00:00 [running]> on host 7bd2786c5ce5
[2023-05-23T22:11:38.979+0000] {taskinstance.py:1592} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=algolia_test
AIRFLOW_CTX_TASK_ID=download_csv_file
AIRFLOW_CTX_EXECUTION_DATE=2019-04-03T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2019-04-03T00:00:00+00:00
[2023-05-23T22:11:38.981+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:204: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2023-05-23T22:11:38.982+0000] {logging_mixin.py:137} INFO - 2019-04-03
[2023-05-23T22:11:40.331+0000] {taskinstance.py:1851} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/decorators/base.py", line 188, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 193, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/algolia-dag.py", line 37, in download_csv_file
    src_client.download_file(object_key, f'/tmp/{object_key}')
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/s3/inject.py", line 283, in bucket_download_file
    Config=Config,
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/s3/inject.py", line 195, in download_file
    callback=Callback,
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/s3/transfer.py", line 320, in download_file
    future.result()
  File "/home/airflow/.local/lib/python3.7/site-packages/s3transfer/futures.py", line 103, in result
    return self._coordinator.result()
  File "/home/airflow/.local/lib/python3.7/site-packages/s3transfer/futures.py", line 266, in result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/s3transfer/tasks.py", line 269, in _main
    self._submit(transfer_future=transfer_future, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/s3transfer/download.py", line 357, in _submit
    **transfer_future.meta.call_args.extra_args,
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 515, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 934, in _make_api_call
    raise error_class(parsed_response, operation_name)
botocore.exceptions.ClientError: An error occurred (404) when calling the HeadObject operation: Not Found
[2023-05-23T22:11:40.342+0000] {taskinstance.py:1406} INFO - Marking task as FAILED. dag_id=algolia_test, task_id=download_csv_file, execution_date=20190403T000000, start_date=20230523T221138, end_date=20230523T221140
[2023-05-23T22:11:40.350+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 71 for task download_csv_file (An error occurred (404) when calling the HeadObject operation: Not Found; 338)
[2023-05-23T22:11:40.422+0000] {local_task_job.py:159} INFO - Task exited with return code 1
[2023-05-23T22:11:40.443+0000] {taskinstance.py:2623} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-05-23T22:13:15.440+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: algolia_test.download_csv_file scheduled__2019-04-03T00:00:00+00:00 [queued]>
[2023-05-23T22:13:15.469+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: algolia_test.download_csv_file scheduled__2019-04-03T00:00:00+00:00 [queued]>
[2023-05-23T22:13:15.470+0000] {taskinstance.py:1362} INFO - 
--------------------------------------------------------------------------------
[2023-05-23T22:13:15.475+0000] {taskinstance.py:1363} INFO - Starting attempt 1 of 1
[2023-05-23T22:13:15.476+0000] {taskinstance.py:1364} INFO - 
--------------------------------------------------------------------------------
[2023-05-23T22:13:15.506+0000] {taskinstance.py:1383} INFO - Executing <Task(_PythonDecoratedOperator): download_csv_file> on 2019-04-03 00:00:00+00:00
[2023-05-23T22:13:15.512+0000] {standard_task_runner.py:55} INFO - Started process 478 to run task
[2023-05-23T22:13:15.549+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'algolia_test', 'download_csv_file', 'scheduled__2019-04-03T00:00:00+00:00', '--job-id', '86', '--raw', '--subdir', 'DAGS_FOLDER/algolia-dag.py', '--cfg-path', '/tmp/tmpj_qrnbx5']
[2023-05-23T22:13:15.558+0000] {standard_task_runner.py:83} INFO - Job 86: Subtask download_csv_file
[2023-05-23T22:13:15.604+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/configuration.py:545: DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
  option = self._get_environment_variables(deprecated_key, deprecated_section, key, section)

[2023-05-23T22:13:15.726+0000] {task_command.py:376} INFO - Running <TaskInstance: algolia_test.download_csv_file scheduled__2019-04-03T00:00:00+00:00 [running]> on host 7bd2786c5ce5
[2023-05-23T22:13:15.841+0000] {taskinstance.py:1592} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=algolia_test
AIRFLOW_CTX_TASK_ID=download_csv_file
AIRFLOW_CTX_EXECUTION_DATE=2019-04-03T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2019-04-03T00:00:00+00:00
[2023-05-23T22:13:15.842+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:204: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2023-05-23T22:13:15.844+0000] {logging_mixin.py:137} INFO - 2019-04-03
[2023-05-23T22:13:16.980+0000] {taskinstance.py:1851} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/decorators/base.py", line 188, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 193, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/algolia-dag.py", line 37, in download_csv_file
    src_client.download_file(object_key, f'/tmp/{object_key}')
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/s3/inject.py", line 283, in bucket_download_file
    Config=Config,
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/s3/inject.py", line 195, in download_file
    callback=Callback,
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/s3/transfer.py", line 320, in download_file
    future.result()
  File "/home/airflow/.local/lib/python3.7/site-packages/s3transfer/futures.py", line 103, in result
    return self._coordinator.result()
  File "/home/airflow/.local/lib/python3.7/site-packages/s3transfer/futures.py", line 266, in result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/s3transfer/tasks.py", line 269, in _main
    self._submit(transfer_future=transfer_future, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/s3transfer/download.py", line 357, in _submit
    **transfer_future.meta.call_args.extra_args,
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 515, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 934, in _make_api_call
    raise error_class(parsed_response, operation_name)
botocore.exceptions.ClientError: An error occurred (404) when calling the HeadObject operation: Not Found
[2023-05-23T22:13:16.990+0000] {taskinstance.py:1406} INFO - Marking task as FAILED. dag_id=algolia_test, task_id=download_csv_file, execution_date=20190403T000000, start_date=20230523T221315, end_date=20230523T221316
[2023-05-23T22:13:16.997+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 86 for task download_csv_file (An error occurred (404) when calling the HeadObject operation: Not Found; 478)
[2023-05-23T22:13:17.039+0000] {local_task_job.py:159} INFO - Task exited with return code 1
[2023-05-23T22:13:17.062+0000] {taskinstance.py:2623} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-05-23T22:28:52.902+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: algolia_test.download_csv_file scheduled__2019-04-03T00:00:00+00:00 [queued]>
[2023-05-23T22:28:52.924+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: algolia_test.download_csv_file scheduled__2019-04-03T00:00:00+00:00 [queued]>
[2023-05-23T22:28:52.925+0000] {taskinstance.py:1362} INFO - 
--------------------------------------------------------------------------------
[2023-05-23T22:28:52.925+0000] {taskinstance.py:1363} INFO - Starting attempt 1 of 1
[2023-05-23T22:28:52.925+0000] {taskinstance.py:1364} INFO - 
--------------------------------------------------------------------------------
[2023-05-23T22:28:52.961+0000] {taskinstance.py:1383} INFO - Executing <Task(_PythonDecoratedOperator): download_csv_file> on 2019-04-03 00:00:00+00:00
[2023-05-23T22:28:52.972+0000] {standard_task_runner.py:55} INFO - Started process 1352 to run task
[2023-05-23T22:28:52.996+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'algolia_test', 'download_csv_file', 'scheduled__2019-04-03T00:00:00+00:00', '--job-id', '109', '--raw', '--subdir', 'DAGS_FOLDER/algolia-dag.py', '--cfg-path', '/tmp/tmph0_0ed_o']
[2023-05-23T22:28:53.004+0000] {standard_task_runner.py:83} INFO - Job 109: Subtask download_csv_file
[2023-05-23T22:28:53.029+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/configuration.py:545: DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
  option = self._get_environment_variables(deprecated_key, deprecated_section, key, section)

[2023-05-23T22:28:53.121+0000] {task_command.py:376} INFO - Running <TaskInstance: algolia_test.download_csv_file scheduled__2019-04-03T00:00:00+00:00 [running]> on host 7bd2786c5ce5
[2023-05-23T22:28:53.248+0000] {taskinstance.py:1592} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=algolia_test
AIRFLOW_CTX_TASK_ID=download_csv_file
AIRFLOW_CTX_EXECUTION_DATE=2019-04-03T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2019-04-03T00:00:00+00:00
[2023-05-23T22:28:53.252+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:204: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2023-05-23T22:28:53.254+0000] {logging_mixin.py:137} INFO - 2019-04-03
[2023-05-23T22:28:54.412+0000] {taskinstance.py:1851} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/decorators/base.py", line 188, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 193, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/algolia-dag.py", line 37, in download_csv_file
    src_client.download_file(object_key, f'/tmp/{object_key}')
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/s3/inject.py", line 283, in bucket_download_file
    Config=Config,
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/s3/inject.py", line 195, in download_file
    callback=Callback,
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/s3/transfer.py", line 320, in download_file
    future.result()
  File "/home/airflow/.local/lib/python3.7/site-packages/s3transfer/futures.py", line 103, in result
    return self._coordinator.result()
  File "/home/airflow/.local/lib/python3.7/site-packages/s3transfer/futures.py", line 266, in result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/s3transfer/tasks.py", line 269, in _main
    self._submit(transfer_future=transfer_future, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/s3transfer/download.py", line 357, in _submit
    **transfer_future.meta.call_args.extra_args,
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 515, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 934, in _make_api_call
    raise error_class(parsed_response, operation_name)
botocore.exceptions.ClientError: An error occurred (404) when calling the HeadObject operation: Not Found
[2023-05-23T22:28:54.458+0000] {taskinstance.py:1406} INFO - Marking task as FAILED. dag_id=algolia_test, task_id=download_csv_file, execution_date=20190403T000000, start_date=20230523T222852, end_date=20230523T222854
[2023-05-23T22:28:54.485+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 109 for task download_csv_file (An error occurred (404) when calling the HeadObject operation: Not Found; 1352)
[2023-05-23T22:28:54.565+0000] {local_task_job.py:159} INFO - Task exited with return code 1
[2023-05-23T22:28:54.590+0000] {taskinstance.py:2623} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-05-23T22:33:34.261+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: algolia_test.download_csv_file scheduled__2019-04-03T00:00:00+00:00 [queued]>
[2023-05-23T22:33:34.285+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: algolia_test.download_csv_file scheduled__2019-04-03T00:00:00+00:00 [queued]>
[2023-05-23T22:33:34.286+0000] {taskinstance.py:1362} INFO - 
--------------------------------------------------------------------------------
[2023-05-23T22:33:34.286+0000] {taskinstance.py:1363} INFO - Starting attempt 1 of 1
[2023-05-23T22:33:34.287+0000] {taskinstance.py:1364} INFO - 
--------------------------------------------------------------------------------
[2023-05-23T22:33:34.319+0000] {taskinstance.py:1383} INFO - Executing <Task(_PythonDecoratedOperator): download_csv_file> on 2019-04-03 00:00:00+00:00
[2023-05-23T22:33:34.349+0000] {standard_task_runner.py:55} INFO - Started process 1664 to run task
[2023-05-23T22:33:34.367+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'algolia_test', 'download_csv_file', 'scheduled__2019-04-03T00:00:00+00:00', '--job-id', '129', '--raw', '--subdir', 'DAGS_FOLDER/algolia-dag.py', '--cfg-path', '/tmp/tmpyfb7z4n9']
[2023-05-23T22:33:34.393+0000] {standard_task_runner.py:83} INFO - Job 129: Subtask download_csv_file
[2023-05-23T22:33:34.423+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/configuration.py:545: DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
  option = self._get_environment_variables(deprecated_key, deprecated_section, key, section)

[2023-05-23T22:33:34.532+0000] {task_command.py:376} INFO - Running <TaskInstance: algolia_test.download_csv_file scheduled__2019-04-03T00:00:00+00:00 [running]> on host 7bd2786c5ce5
[2023-05-23T22:33:34.666+0000] {taskinstance.py:1592} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=algolia_test
AIRFLOW_CTX_TASK_ID=download_csv_file
AIRFLOW_CTX_EXECUTION_DATE=2019-04-03T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2019-04-03T00:00:00+00:00
[2023-05-23T22:33:34.668+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:204: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2023-05-23T22:33:34.669+0000] {logging_mixin.py:137} INFO - 2019-04-03
[2023-05-23T22:33:36.048+0000] {taskinstance.py:1851} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/decorators/base.py", line 188, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 193, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/algolia-dag.py", line 37, in download_csv_file
    src_client.download_file(object_key, f'/tmp/{object_key}')
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/s3/inject.py", line 283, in bucket_download_file
    Config=Config,
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/s3/inject.py", line 195, in download_file
    callback=Callback,
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/s3/transfer.py", line 320, in download_file
    future.result()
  File "/home/airflow/.local/lib/python3.7/site-packages/s3transfer/futures.py", line 103, in result
    return self._coordinator.result()
  File "/home/airflow/.local/lib/python3.7/site-packages/s3transfer/futures.py", line 266, in result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/s3transfer/tasks.py", line 269, in _main
    self._submit(transfer_future=transfer_future, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/s3transfer/download.py", line 357, in _submit
    **transfer_future.meta.call_args.extra_args,
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 515, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 934, in _make_api_call
    raise error_class(parsed_response, operation_name)
botocore.exceptions.ClientError: An error occurred (404) when calling the HeadObject operation: Not Found
[2023-05-23T22:33:36.059+0000] {taskinstance.py:1406} INFO - Marking task as FAILED. dag_id=algolia_test, task_id=download_csv_file, execution_date=20190403T000000, start_date=20230523T223334, end_date=20230523T223336
[2023-05-23T22:33:36.066+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 129 for task download_csv_file (An error occurred (404) when calling the HeadObject operation: Not Found; 1664)
[2023-05-23T22:33:36.132+0000] {local_task_job.py:159} INFO - Task exited with return code 1
[2023-05-23T22:33:36.151+0000] {taskinstance.py:2623} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-05-23T22:38:40.627+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: algolia_test.download_csv_file scheduled__2019-04-03T00:00:00+00:00 [queued]>
[2023-05-23T22:38:40.642+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: algolia_test.download_csv_file scheduled__2019-04-03T00:00:00+00:00 [queued]>
[2023-05-23T22:38:40.643+0000] {taskinstance.py:1362} INFO - 
--------------------------------------------------------------------------------
[2023-05-23T22:38:40.643+0000] {taskinstance.py:1363} INFO - Starting attempt 1 of 1
[2023-05-23T22:38:40.643+0000] {taskinstance.py:1364} INFO - 
--------------------------------------------------------------------------------
[2023-05-23T22:38:40.666+0000] {taskinstance.py:1383} INFO - Executing <Task(_PythonDecoratedOperator): download_csv_file> on 2019-04-03 00:00:00+00:00
[2023-05-23T22:38:40.677+0000] {standard_task_runner.py:55} INFO - Started process 1990 to run task
[2023-05-23T22:38:40.700+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'algolia_test', 'download_csv_file', 'scheduled__2019-04-03T00:00:00+00:00', '--job-id', '147', '--raw', '--subdir', 'DAGS_FOLDER/algolia-dag.py', '--cfg-path', '/tmp/tmp4eh0a80g']
[2023-05-23T22:38:40.705+0000] {standard_task_runner.py:83} INFO - Job 147: Subtask download_csv_file
[2023-05-23T22:38:40.777+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/configuration.py:545: DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
  option = self._get_environment_variables(deprecated_key, deprecated_section, key, section)

[2023-05-23T22:38:40.902+0000] {task_command.py:376} INFO - Running <TaskInstance: algolia_test.download_csv_file scheduled__2019-04-03T00:00:00+00:00 [running]> on host 7bd2786c5ce5
[2023-05-23T22:38:41.002+0000] {taskinstance.py:1592} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=algolia_test
AIRFLOW_CTX_TASK_ID=download_csv_file
AIRFLOW_CTX_EXECUTION_DATE=2019-04-03T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2019-04-03T00:00:00+00:00
[2023-05-23T22:38:41.005+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:204: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2023-05-23T22:38:41.006+0000] {logging_mixin.py:137} INFO - 2019-04-03
[2023-05-23T22:38:42.122+0000] {taskinstance.py:1851} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/decorators/base.py", line 188, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 193, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/algolia-dag.py", line 37, in download_csv_file
    src_client.download_file(object_key, f'/tmp/{object_key}')
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/s3/inject.py", line 283, in bucket_download_file
    Config=Config,
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/s3/inject.py", line 195, in download_file
    callback=Callback,
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/s3/transfer.py", line 320, in download_file
    future.result()
  File "/home/airflow/.local/lib/python3.7/site-packages/s3transfer/futures.py", line 103, in result
    return self._coordinator.result()
  File "/home/airflow/.local/lib/python3.7/site-packages/s3transfer/futures.py", line 266, in result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/s3transfer/tasks.py", line 269, in _main
    self._submit(transfer_future=transfer_future, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/s3transfer/download.py", line 357, in _submit
    **transfer_future.meta.call_args.extra_args,
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 515, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 934, in _make_api_call
    raise error_class(parsed_response, operation_name)
botocore.exceptions.ClientError: An error occurred (404) when calling the HeadObject operation: Not Found
[2023-05-23T22:38:42.138+0000] {taskinstance.py:1406} INFO - Marking task as FAILED. dag_id=algolia_test, task_id=download_csv_file, execution_date=20190403T000000, start_date=20230523T223840, end_date=20230523T223842
[2023-05-23T22:38:42.148+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 147 for task download_csv_file (An error occurred (404) when calling the HeadObject operation: Not Found; 1990)
[2023-05-23T22:38:42.206+0000] {local_task_job.py:159} INFO - Task exited with return code 1
[2023-05-23T22:38:42.225+0000] {taskinstance.py:2623} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-05-24T10:56:16.186+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: algolia_test.download_csv_file scheduled__2019-04-03T00:00:00+00:00 [queued]>
[2023-05-24T10:56:16.194+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: algolia_test.download_csv_file scheduled__2019-04-03T00:00:00+00:00 [queued]>
[2023-05-24T10:56:16.197+0000] {taskinstance.py:1362} INFO - 
--------------------------------------------------------------------------------
[2023-05-24T10:56:16.197+0000] {taskinstance.py:1363} INFO - Starting attempt 1 of 1
[2023-05-24T10:56:16.198+0000] {taskinstance.py:1364} INFO - 
--------------------------------------------------------------------------------
[2023-05-24T10:56:16.219+0000] {taskinstance.py:1383} INFO - Executing <Task(_PythonDecoratedOperator): download_csv_file> on 2019-04-03 00:00:00+00:00
[2023-05-24T10:56:16.232+0000] {standard_task_runner.py:55} INFO - Started process 5050 to run task
[2023-05-24T10:56:16.258+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'algolia_test', 'download_csv_file', 'scheduled__2019-04-03T00:00:00+00:00', '--job-id', '166', '--raw', '--subdir', 'DAGS_FOLDER/algolia-dag.py', '--cfg-path', '/tmp/tmpr9k45fh2']
[2023-05-24T10:56:16.290+0000] {standard_task_runner.py:83} INFO - Job 166: Subtask download_csv_file
[2023-05-24T10:56:16.343+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/configuration.py:545: DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
  option = self._get_environment_variables(deprecated_key, deprecated_section, key, section)

[2023-05-24T10:56:16.503+0000] {task_command.py:376} INFO - Running <TaskInstance: algolia_test.download_csv_file scheduled__2019-04-03T00:00:00+00:00 [running]> on host 7bd2786c5ce5
[2023-05-24T10:56:16.679+0000] {taskinstance.py:1592} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=algolia_test
AIRFLOW_CTX_TASK_ID=download_csv_file
AIRFLOW_CTX_EXECUTION_DATE=2019-04-03T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2019-04-03T00:00:00+00:00
[2023-05-24T10:56:16.681+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:204: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2023-05-24T10:56:18.042+0000] {taskinstance.py:1851} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/decorators/base.py", line 188, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 193, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/algolia-dag.py", line 38, in download_csv_file
    src_client.download_file(object_key, f'/tmp/{object_key}')
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/s3/inject.py", line 283, in bucket_download_file
    Config=Config,
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/s3/inject.py", line 195, in download_file
    callback=Callback,
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/s3/transfer.py", line 320, in download_file
    future.result()
  File "/home/airflow/.local/lib/python3.7/site-packages/s3transfer/futures.py", line 103, in result
    return self._coordinator.result()
  File "/home/airflow/.local/lib/python3.7/site-packages/s3transfer/futures.py", line 266, in result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/s3transfer/tasks.py", line 269, in _main
    self._submit(transfer_future=transfer_future, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/s3transfer/download.py", line 357, in _submit
    **transfer_future.meta.call_args.extra_args,
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 515, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 934, in _make_api_call
    raise error_class(parsed_response, operation_name)
botocore.exceptions.ClientError: An error occurred (404) when calling the HeadObject operation: Not Found
[2023-05-24T10:56:18.067+0000] {taskinstance.py:1406} INFO - Marking task as FAILED. dag_id=algolia_test, task_id=download_csv_file, execution_date=20190403T000000, start_date=20230524T105616, end_date=20230524T105618
[2023-05-24T10:56:18.082+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 166 for task download_csv_file (An error occurred (404) when calling the HeadObject operation: Not Found; 5050)
[2023-05-24T10:56:18.129+0000] {local_task_job.py:159} INFO - Task exited with return code 1
[2023-05-24T10:56:18.150+0000] {taskinstance.py:2623} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-05-24T11:25:43.988+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: algolia_test.download_csv_file scheduled__2019-04-03T00:00:00+00:00 [queued]>
[2023-05-24T11:25:44.122+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: algolia_test.download_csv_file scheduled__2019-04-03T00:00:00+00:00 [queued]>
[2023-05-24T11:25:44.138+0000] {taskinstance.py:1362} INFO - 
--------------------------------------------------------------------------------
[2023-05-24T11:25:44.142+0000] {taskinstance.py:1363} INFO - Starting attempt 1 of 1
[2023-05-24T11:25:44.143+0000] {taskinstance.py:1364} INFO - 
--------------------------------------------------------------------------------
[2023-05-24T11:25:44.158+0000] {taskinstance.py:1383} INFO - Executing <Task(_PythonDecoratedOperator): download_csv_file> on 2019-04-03 00:00:00+00:00
[2023-05-24T11:25:44.168+0000] {standard_task_runner.py:55} INFO - Started process 6589 to run task
[2023-05-24T11:25:44.225+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'algolia_test', 'download_csv_file', 'scheduled__2019-04-03T00:00:00+00:00', '--job-id', '185', '--raw', '--subdir', 'DAGS_FOLDER/algolia-dag.py', '--cfg-path', '/tmp/tmpal264dx8']
[2023-05-24T11:25:44.230+0000] {standard_task_runner.py:83} INFO - Job 185: Subtask download_csv_file
[2023-05-24T11:25:44.311+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/configuration.py:545: DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
  option = self._get_environment_variables(deprecated_key, deprecated_section, key, section)

[2023-05-24T11:25:44.441+0000] {task_command.py:376} INFO - Running <TaskInstance: algolia_test.download_csv_file scheduled__2019-04-03T00:00:00+00:00 [running]> on host 7bd2786c5ce5
[2023-05-24T11:25:44.582+0000] {taskinstance.py:1592} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=algolia_test
AIRFLOW_CTX_TASK_ID=download_csv_file
AIRFLOW_CTX_EXECUTION_DATE=2019-04-03T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2019-04-03T00:00:00+00:00
[2023-05-24T11:25:44.583+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:204: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2023-05-24T11:25:45.608+0000] {taskinstance.py:1851} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/decorators/base.py", line 188, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 193, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/algolia-dag.py", line 38, in download_csv_file
    src_client.download_file(object_key, f'/tmp/{object_key}')
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/s3/inject.py", line 283, in bucket_download_file
    Config=Config,
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/s3/inject.py", line 195, in download_file
    callback=Callback,
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/s3/transfer.py", line 320, in download_file
    future.result()
  File "/home/airflow/.local/lib/python3.7/site-packages/s3transfer/futures.py", line 103, in result
    return self._coordinator.result()
  File "/home/airflow/.local/lib/python3.7/site-packages/s3transfer/futures.py", line 266, in result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/s3transfer/tasks.py", line 269, in _main
    self._submit(transfer_future=transfer_future, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/s3transfer/download.py", line 357, in _submit
    **transfer_future.meta.call_args.extra_args,
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 515, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 934, in _make_api_call
    raise error_class(parsed_response, operation_name)
botocore.exceptions.ClientError: An error occurred (404) when calling the HeadObject operation: Not Found
[2023-05-24T11:25:45.619+0000] {taskinstance.py:1406} INFO - Marking task as FAILED. dag_id=algolia_test, task_id=download_csv_file, execution_date=20190403T000000, start_date=20230524T112544, end_date=20230524T112545
[2023-05-24T11:25:45.626+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 185 for task download_csv_file (An error occurred (404) when calling the HeadObject operation: Not Found; 6589)
[2023-05-24T11:25:45.686+0000] {local_task_job.py:159} INFO - Task exited with return code 1
[2023-05-24T11:25:45.742+0000] {taskinstance.py:2623} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-05-24T11:27:41.648+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: algolia_test.download_csv_file scheduled__2019-04-03T00:00:00+00:00 [queued]>
[2023-05-24T11:27:41.664+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: algolia_test.download_csv_file scheduled__2019-04-03T00:00:00+00:00 [queued]>
[2023-05-24T11:27:41.665+0000] {taskinstance.py:1362} INFO - 
--------------------------------------------------------------------------------
[2023-05-24T11:27:41.666+0000] {taskinstance.py:1363} INFO - Starting attempt 1 of 1
[2023-05-24T11:27:41.667+0000] {taskinstance.py:1364} INFO - 
--------------------------------------------------------------------------------
[2023-05-24T11:27:41.713+0000] {taskinstance.py:1383} INFO - Executing <Task(_PythonDecoratedOperator): download_csv_file> on 2019-04-03 00:00:00+00:00
[2023-05-24T11:27:41.720+0000] {standard_task_runner.py:55} INFO - Started process 6740 to run task
[2023-05-24T11:27:41.740+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'algolia_test', 'download_csv_file', 'scheduled__2019-04-03T00:00:00+00:00', '--job-id', '198', '--raw', '--subdir', 'DAGS_FOLDER/algolia-dag.py', '--cfg-path', '/tmp/tmp4ecbteax']
[2023-05-24T11:27:41.760+0000] {standard_task_runner.py:83} INFO - Job 198: Subtask download_csv_file
[2023-05-24T11:27:41.793+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/configuration.py:545: DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
  option = self._get_environment_variables(deprecated_key, deprecated_section, key, section)

[2023-05-24T11:27:41.980+0000] {task_command.py:376} INFO - Running <TaskInstance: algolia_test.download_csv_file scheduled__2019-04-03T00:00:00+00:00 [running]> on host 7bd2786c5ce5
[2023-05-24T11:27:42.163+0000] {taskinstance.py:1592} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=algolia_test
AIRFLOW_CTX_TASK_ID=download_csv_file
AIRFLOW_CTX_EXECUTION_DATE=2019-04-03T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2019-04-03T00:00:00+00:00
[2023-05-24T11:27:42.167+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:204: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2023-05-24T11:27:43.965+0000] {taskinstance.py:1851} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/decorators/base.py", line 188, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 193, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/algolia-dag.py", line 38, in download_csv_file
    src_client.download_file(object_key, f'/tmp/{object_key}')
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/s3/inject.py", line 283, in bucket_download_file
    Config=Config,
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/s3/inject.py", line 195, in download_file
    callback=Callback,
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/s3/transfer.py", line 320, in download_file
    future.result()
  File "/home/airflow/.local/lib/python3.7/site-packages/s3transfer/futures.py", line 103, in result
    return self._coordinator.result()
  File "/home/airflow/.local/lib/python3.7/site-packages/s3transfer/futures.py", line 266, in result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/s3transfer/tasks.py", line 269, in _main
    self._submit(transfer_future=transfer_future, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/s3transfer/download.py", line 357, in _submit
    **transfer_future.meta.call_args.extra_args,
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 515, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 934, in _make_api_call
    raise error_class(parsed_response, operation_name)
botocore.exceptions.ClientError: An error occurred (404) when calling the HeadObject operation: Not Found
[2023-05-24T11:27:43.988+0000] {taskinstance.py:1406} INFO - Marking task as FAILED. dag_id=algolia_test, task_id=download_csv_file, execution_date=20190403T000000, start_date=20230524T112741, end_date=20230524T112743
[2023-05-24T11:27:44.016+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 198 for task download_csv_file (An error occurred (404) when calling the HeadObject operation: Not Found; 6740)
[2023-05-24T11:27:44.110+0000] {local_task_job.py:159} INFO - Task exited with return code 1
[2023-05-24T11:27:44.160+0000] {taskinstance.py:2623} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-05-24T11:29:34.937+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: algolia_test.download_csv_file scheduled__2019-04-03T00:00:00+00:00 [queued]>
[2023-05-24T11:29:34.976+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: algolia_test.download_csv_file scheduled__2019-04-03T00:00:00+00:00 [queued]>
[2023-05-24T11:29:34.977+0000] {taskinstance.py:1362} INFO - 
--------------------------------------------------------------------------------
[2023-05-24T11:29:34.978+0000] {taskinstance.py:1363} INFO - Starting attempt 1 of 1
[2023-05-24T11:29:34.979+0000] {taskinstance.py:1364} INFO - 
--------------------------------------------------------------------------------
[2023-05-24T11:29:35.014+0000] {taskinstance.py:1383} INFO - Executing <Task(_PythonDecoratedOperator): download_csv_file> on 2019-04-03 00:00:00+00:00
[2023-05-24T11:29:35.021+0000] {standard_task_runner.py:55} INFO - Started process 6883 to run task
[2023-05-24T11:29:35.053+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'algolia_test', 'download_csv_file', 'scheduled__2019-04-03T00:00:00+00:00', '--job-id', '211', '--raw', '--subdir', 'DAGS_FOLDER/algolia-dag.py', '--cfg-path', '/tmp/tmp284ktkuy']
[2023-05-24T11:29:35.057+0000] {standard_task_runner.py:83} INFO - Job 211: Subtask download_csv_file
[2023-05-24T11:29:35.114+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/configuration.py:545: DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
  option = self._get_environment_variables(deprecated_key, deprecated_section, key, section)

[2023-05-24T11:29:35.263+0000] {task_command.py:376} INFO - Running <TaskInstance: algolia_test.download_csv_file scheduled__2019-04-03T00:00:00+00:00 [running]> on host 7bd2786c5ce5
[2023-05-24T11:29:35.438+0000] {taskinstance.py:1592} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=algolia_test
AIRFLOW_CTX_TASK_ID=download_csv_file
AIRFLOW_CTX_EXECUTION_DATE=2019-04-03T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2019-04-03T00:00:00+00:00
[2023-05-24T11:29:35.440+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:204: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2023-05-24T11:29:36.463+0000] {taskinstance.py:1851} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/decorators/base.py", line 188, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 193, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/algolia-dag.py", line 38, in download_csv_file
    src_client.download_file(object_key, f'/tmp/{object_key}')
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/s3/inject.py", line 283, in bucket_download_file
    Config=Config,
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/s3/inject.py", line 195, in download_file
    callback=Callback,
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/s3/transfer.py", line 320, in download_file
    future.result()
  File "/home/airflow/.local/lib/python3.7/site-packages/s3transfer/futures.py", line 103, in result
    return self._coordinator.result()
  File "/home/airflow/.local/lib/python3.7/site-packages/s3transfer/futures.py", line 266, in result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/s3transfer/tasks.py", line 269, in _main
    self._submit(transfer_future=transfer_future, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/s3transfer/download.py", line 357, in _submit
    **transfer_future.meta.call_args.extra_args,
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 515, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 934, in _make_api_call
    raise error_class(parsed_response, operation_name)
botocore.exceptions.ClientError: An error occurred (404) when calling the HeadObject operation: Not Found
[2023-05-24T11:29:36.479+0000] {taskinstance.py:1406} INFO - Marking task as FAILED. dag_id=algolia_test, task_id=download_csv_file, execution_date=20190403T000000, start_date=20230524T112934, end_date=20230524T112936
[2023-05-24T11:29:36.492+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 211 for task download_csv_file (An error occurred (404) when calling the HeadObject operation: Not Found; 6883)
[2023-05-24T11:29:36.535+0000] {local_task_job.py:159} INFO - Task exited with return code 1
[2023-05-24T11:29:36.568+0000] {taskinstance.py:2623} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-05-26T12:12:22.030+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: algolia_test.download_csv_file scheduled__2019-04-03T00:00:00+00:00 [queued]>
[2023-05-26T12:12:22.171+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: algolia_test.download_csv_file scheduled__2019-04-03T00:00:00+00:00 [queued]>
[2023-05-26T12:12:22.178+0000] {taskinstance.py:1362} INFO - 
--------------------------------------------------------------------------------
[2023-05-26T12:12:22.201+0000] {taskinstance.py:1363} INFO - Starting attempt 1 of 1
[2023-05-26T12:12:22.202+0000] {taskinstance.py:1364} INFO - 
--------------------------------------------------------------------------------
[2023-05-26T12:12:22.298+0000] {taskinstance.py:1383} INFO - Executing <Task(_PythonDecoratedOperator): download_csv_file> on 2019-04-03 00:00:00+00:00
[2023-05-26T12:12:22.336+0000] {standard_task_runner.py:55} INFO - Started process 514 to run task
[2023-05-26T12:12:22.383+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'algolia_test', 'download_csv_file', 'scheduled__2019-04-03T00:00:00+00:00', '--job-id', '236', '--raw', '--subdir', 'DAGS_FOLDER/algolia-dag.py', '--cfg-path', '/tmp/tmpw_y_387g']
[2023-05-26T12:12:22.393+0000] {standard_task_runner.py:83} INFO - Job 236: Subtask download_csv_file
[2023-05-26T12:12:22.515+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/configuration.py:545: DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
  option = self._get_environment_variables(deprecated_key, deprecated_section, key, section)

[2023-05-26T12:12:23.200+0000] {task_command.py:376} INFO - Running <TaskInstance: algolia_test.download_csv_file scheduled__2019-04-03T00:00:00+00:00 [running]> on host b55299475a02
[2023-05-26T12:12:23.536+0000] {taskinstance.py:1592} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=algolia_test
AIRFLOW_CTX_TASK_ID=download_csv_file
AIRFLOW_CTX_EXECUTION_DATE=2019-04-03T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2019-04-03T00:00:00+00:00
[2023-05-26T12:12:23.543+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:204: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2023-05-26T12:12:27.069+0000] {taskinstance.py:1851} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/decorators/base.py", line 188, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 193, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/algolia-dag.py", line 39, in download_csv_file
    src_client.download_file(object_key, f'/tmp/{object_key}')
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/s3/inject.py", line 283, in bucket_download_file
    Config=Config,
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/s3/inject.py", line 195, in download_file
    callback=Callback,
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/s3/transfer.py", line 320, in download_file
    future.result()
  File "/home/airflow/.local/lib/python3.7/site-packages/s3transfer/futures.py", line 103, in result
    return self._coordinator.result()
  File "/home/airflow/.local/lib/python3.7/site-packages/s3transfer/futures.py", line 266, in result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/s3transfer/tasks.py", line 269, in _main
    self._submit(transfer_future=transfer_future, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/s3transfer/download.py", line 357, in _submit
    **transfer_future.meta.call_args.extra_args,
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 515, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 934, in _make_api_call
    raise error_class(parsed_response, operation_name)
botocore.exceptions.ClientError: An error occurred (404) when calling the HeadObject operation: Not Found
[2023-05-26T12:12:27.109+0000] {taskinstance.py:1406} INFO - Marking task as FAILED. dag_id=algolia_test, task_id=download_csv_file, execution_date=20190403T000000, start_date=20230526T121222, end_date=20230526T121227
[2023-05-26T12:12:27.145+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 236 for task download_csv_file (An error occurred (404) when calling the HeadObject operation: Not Found; 514)
[2023-05-26T12:12:27.235+0000] {local_task_job.py:159} INFO - Task exited with return code 1
[2023-05-26T12:12:27.290+0000] {taskinstance.py:2623} INFO - 0 downstream tasks scheduled from follow-on schedule check
